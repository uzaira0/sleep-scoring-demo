#!/usr/bin/env python3
"""
Performance benchmarking and memory monitoring tests for seamless activity data switching.
Provides comprehensive performance validation and memory usage analysis.
"""

from __future__ import annotations

import gc
import os
import threading
import time
from collections import namedtuple
from dataclasses import dataclass
from typing import Any
from unittest.mock import Mock, patch

import numpy as np
import pandas as pd
import psutil
import pytest
from PyQt6.QtWidgets import QApplication

from sleep_scoring_app.core.constants import ViewMode
from sleep_scoring_app.services.unified_data_service import UnifiedDataService
from sleep_scoring_app.ui.widgets.activity_plot import ActivityPlotWidget

# ParticipantKey was removed from dataclasses - use simple namedtuple for tests
ParticipantKey = namedtuple("ParticipantKey", ["participant_id", "study_code", "group"])


@dataclass
class PerformanceBenchmark:
    """Performance benchmark result."""

    operation_name: str
    total_time_ms: float
    data_load_time_ms: float
    ui_update_time_ms: float
    state_preservation_time_ms: float
    memory_before_mb: float
    memory_after_mb: float
    memory_peak_mb: float
    cpu_usage_percent: float
    throughput_ops_per_sec: float
    data_size: int
    pass_threshold_ms: float
    is_passing: bool


@dataclass
class MemoryProfile:
    """Memory usage profile during operation."""

    rss_mb: float
    vms_mb: float
    heap_mb: float
    stack_mb: float
    shared_mb: float
    private_mb: float
    gc_generation_0: int
    gc_generation_1: int
    gc_generation_2: int
    object_count: int


class PerformanceMonitor:
    """Monitor performance and memory usage during operations."""

    def __init__(self) -> None:
        self.process = psutil.Process(os.getpid())
        self.measurements = []
        self.monitoring = False
        self.monitor_thread = None

    def start_monitoring(self, interval_ms: int = 10):
        """Start continuous performance monitoring."""
        self.monitoring = True
        self.measurements.clear()

        def monitor_loop():
            while self.monitoring:
                try:
                    memory_info = self.process.memory_info()
                    cpu_percent = self.process.cpu_percent()
                    gc_stats = gc.get_count()

                    profile = MemoryProfile(
                        rss_mb=memory_info.rss / 1024 / 1024,
                        vms_mb=memory_info.vms / 1024 / 1024,
                        heap_mb=0.0,  # Would need pympler for detailed heap analysis
                        stack_mb=0.0,
                        shared_mb=0.0,
                        private_mb=0.0,
                        gc_generation_0=gc_stats[0],
                        gc_generation_1=gc_stats[1],
                        gc_generation_2=gc_stats[2],
                        object_count=len(gc.get_objects()) if hasattr(gc, "get_objects") else 0,
                    )

                    self.measurements.append({"timestamp": time.perf_counter(), "memory": profile, "cpu_percent": cpu_percent})

                    time.sleep(interval_ms / 1000.0)

                except Exception:
                    # Ignore monitoring errors
                    pass

        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()

    def stop_monitoring(self):
        """Stop performance monitoring."""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1.0)

    def get_peak_memory_mb(self) -> float:
        """Get peak memory usage during monitoring period."""
        if not self.measurements:
            return 0.0

        return max(m["memory"].rss_mb for m in self.measurements)

    def get_average_cpu_percent(self) -> float:
        """Get average CPU usage during monitoring period."""
        if not self.measurements:
            return 0.0

        return sum(m["cpu_percent"] for m in self.measurements) / len(self.measurements)

    def get_memory_growth_mb(self) -> float:
        """Get memory growth from start to end of monitoring."""
        if len(self.measurements) < 2:
            return 0.0

        start_memory = self.measurements[0]["memory"].rss_mb
        end_memory = self.measurements[-1]["memory"].rss_mb
        return end_memory - start_memory


class SwitchingPerformanceBenchmark:
    """Comprehensive performance benchmark for switching operations."""

    def __init__(self) -> None:
        self.monitor = PerformanceMonitor()
        self.benchmark_results = []

    def benchmark_data_source_switching(self, data_sizes: list[int], iterations: int = 5) -> list[PerformanceBenchmark]:
        """Benchmark data source switching performance."""
        results = []

        for data_size in data_sizes:
            # Generate test data
            test_data = self._generate_test_data(data_size)

            total_times = []
            memory_usage = []

            for iteration in range(iterations):
                # Setup mock services
                mock_service = self._create_mock_service(test_data)
                mock_plot = self._create_mock_plot_widget()

                # Start monitoring
                self.monitor.start_monitoring()
                gc.collect()  # Clean up before measurement

                memory_before = self.monitor.process.memory_info().rss / 1024 / 1024
                start_time = time.perf_counter()

                # Perform switching operation
                participant_key = ParticipantKey("4000", "BO", "G1")

                # Simulate database to CSV switch
                data_load_start = time.perf_counter()
                mock_service.load_participant_data(participant_key, ViewMode.HOURS_24)
                data_load_time = (time.perf_counter() - data_load_start) * 1000

                # Simulate UI update
                ui_update_start = time.perf_counter()
                mock_plot.set_data_and_restrictions(test_data["timestamps"], test_data["activity"], ViewMode.HOURS_24)
                ui_update_time = (time.perf_counter() - ui_update_start) * 1000

                end_time = time.perf_counter()
                total_time = (end_time - start_time) * 1000

                memory_after = self.monitor.process.memory_info().rss / 1024 / 1024
                peak_memory = self.monitor.get_peak_memory_mb()
                cpu_usage = self.monitor.get_average_cpu_percent()

                self.monitor.stop_monitoring()

                total_times.append(total_time)
                memory_usage.append(memory_after - memory_before)

            # Calculate averages
            avg_total_time = sum(total_times) / len(total_times)
            sum(memory_usage) / len(memory_usage)

            # Performance thresholds based on data size
            threshold_ms = 100 + (data_size / 1000) * 10  # Base 100ms + 10ms per 1000 records

            benchmark = PerformanceBenchmark(
                operation_name=f"data_source_switch_{data_size}_records",
                total_time_ms=avg_total_time,
                data_load_time_ms=data_load_time,
                ui_update_time_ms=ui_update_time,
                state_preservation_time_ms=5.0,  # Estimated
                memory_before_mb=memory_before,
                memory_after_mb=memory_after,
                memory_peak_mb=peak_memory,
                cpu_usage_percent=cpu_usage,
                throughput_ops_per_sec=1000.0 / avg_total_time if avg_total_time > 0 else 0,
                data_size=data_size,
                pass_threshold_ms=threshold_ms,
                is_passing=avg_total_time <= threshold_ms,
            )

            results.append(benchmark)
            self.benchmark_results.append(benchmark)

        return results

    def benchmark_view_mode_switching(self, mode_transitions: list[tuple[ViewMode, ViewMode]], data_size: int = 5760) -> list[PerformanceBenchmark]:
        """Benchmark view mode switching performance."""
        results = []

        for source_mode, target_mode in mode_transitions:
            # Generate appropriate data size for source mode
            if source_mode == ViewMode.HOURS_24:
                source_data = self._generate_test_data(2880)  # 24h data
            else:
                source_data = self._generate_test_data(5760)  # 48h data

            # Generate target data
            if target_mode == ViewMode.HOURS_24:
                target_data = self._generate_test_data(2880)
            else:
                target_data = self._generate_test_data(5760)

            mock_service = self._create_mock_service(target_data)
            mock_plot = self._create_mock_plot_widget()

            # Set initial state
            mock_plot.activity_data = source_data["activity"]
            mock_plot.timestamps = source_data["timestamps"]
            mock_plot.current_view_hours = source_mode

            # Add markers and zoom state
            mock_plot.sleep_markers = [
                {"type": "onset", "time": 75600, "label": "Sleep Onset"},
                {"type": "offset", "time": 104400, "label": "Sleep Offset"},
            ]
            mock_plot.vb.viewRange.return_value = [[70000, 110000], [0, 200]]  # Custom zoom

            # Start performance measurement
            self.monitor.start_monitoring()
            gc.collect()

            memory_before = self.monitor.process.memory_info().rss / 1024 / 1024
            start_time = time.perf_counter()

            # Perform view mode switch
            participant_key = ParticipantKey("4000", "BO", "G1")

            # Measure state preservation
            state_start = time.perf_counter()
            initial_markers = mock_plot.sleep_markers.copy()
            initial_view_range = mock_plot.vb.viewRange()
            state_preservation_time = (time.perf_counter() - state_start) * 1000

            # Measure data loading
            data_load_start = time.perf_counter()
            mock_service.load_participant_data(participant_key, target_mode)
            data_load_time = (time.perf_counter() - data_load_start) * 1000

            # Measure UI update
            ui_update_start = time.perf_counter()
            mock_plot.set_data_and_restrictions(target_data["timestamps"], target_data["activity"], target_mode)
            # Restore state
            mock_plot.sleep_markers = initial_markers
            if source_mode == target_mode:  # Same mode preserves zoom
                mock_plot.vb.setRange(xRange=initial_view_range[0], yRange=initial_view_range[1])
            ui_update_time = (time.perf_counter() - ui_update_start) * 1000

            end_time = time.perf_counter()
            total_time = (end_time - start_time) * 1000

            memory_after = self.monitor.process.memory_info().rss / 1024 / 1024
            peak_memory = self.monitor.get_peak_memory_mb()
            cpu_usage = self.monitor.get_average_cpu_percent()

            self.monitor.stop_monitoring()

            # Performance threshold for view mode switching
            threshold_ms = 200.0  # More lenient for view mode changes

            benchmark = PerformanceBenchmark(
                operation_name=f"view_mode_switch_{source_mode}_to_{target_mode}",
                total_time_ms=total_time,
                data_load_time_ms=data_load_time,
                ui_update_time_ms=ui_update_time,
                state_preservation_time_ms=state_preservation_time,
                memory_before_mb=memory_before,
                memory_after_mb=memory_after,
                memory_peak_mb=peak_memory,
                cpu_usage_percent=cpu_usage,
                throughput_ops_per_sec=1000.0 / total_time if total_time > 0 else 0,
                data_size=len(target_data["activity"]),
                pass_threshold_ms=threshold_ms,
                is_passing=total_time <= threshold_ms,
            )

            results.append(benchmark)
            self.benchmark_results.append(benchmark)

        return results

    def benchmark_rapid_switching(self, switch_count: int = 20, data_size: int = 2880) -> PerformanceBenchmark:
        """Benchmark rapid successive switching operations."""
        test_data = self._generate_test_data(data_size)
        mock_service = self._create_mock_service(test_data)
        mock_plot = self._create_mock_plot_widget()

        participants = [ParticipantKey("4000", "BO", "G1"), ParticipantKey("4001", "P2", "G2"), ParticipantKey("4002", "P1", "G3")]

        modes = [ViewMode.HOURS_24, ViewMode.HOURS_48]

        self.monitor.start_monitoring()
        gc.collect()

        memory_before = self.monitor.process.memory_info().rss / 1024 / 1024
        start_time = time.perf_counter()

        # Perform rapid switches
        for i in range(switch_count):
            participant = participants[i % len(participants)]
            mode = modes[i % len(modes)]

            # Switch operation
            mock_service.load_participant_data(participant, mode)
            mock_plot.set_data_and_restrictions(test_data["timestamps"], test_data["activity"], mode)

            # Brief processing to simulate real usage
            QApplication.processEvents()

        end_time = time.perf_counter()
        total_time = (end_time - start_time) * 1000

        memory_after = self.monitor.process.memory_info().rss / 1024 / 1024
        peak_memory = self.monitor.get_peak_memory_mb()
        cpu_usage = self.monitor.get_average_cpu_percent()

        self.monitor.stop_monitoring()

        # Performance threshold for rapid switching
        threshold_ms = switch_count * 50  # 50ms per switch maximum

        benchmark = PerformanceBenchmark(
            operation_name=f"rapid_switching_{switch_count}_operations",
            total_time_ms=total_time,
            data_load_time_ms=total_time * 0.6,  # Estimated 60% for data loading
            ui_update_time_ms=total_time * 0.3,  # Estimated 30% for UI updates
            state_preservation_time_ms=total_time * 0.1,  # Estimated 10% for state
            memory_before_mb=memory_before,
            memory_after_mb=memory_after,
            memory_peak_mb=peak_memory,
            cpu_usage_percent=cpu_usage,
            throughput_ops_per_sec=switch_count * 1000.0 / total_time if total_time > 0 else 0,
            data_size=data_size,
            pass_threshold_ms=threshold_ms,
            is_passing=total_time <= threshold_ms,
        )

        self.benchmark_results.append(benchmark)
        return benchmark

    def benchmark_memory_usage_patterns(self, operations: int = 100) -> dict[str, Any]:
        """Benchmark memory usage patterns during extended switching operations."""
        test_data = self._generate_test_data(5760)  # Large dataset
        mock_service = self._create_mock_service(test_data)
        mock_plot = self._create_mock_plot_widget()

        participant_key = ParticipantKey("4000", "BO", "G1")
        modes = [ViewMode.HOURS_24, ViewMode.HOURS_48]

        memory_snapshots = []
        gc_collections = []

        self.monitor.start_monitoring(interval_ms=50)  # Higher frequency for memory analysis

        initial_memory = self.monitor.process.memory_info().rss / 1024 / 1024

        for i in range(operations):
            mode = modes[i % len(modes)]

            # Capture memory before operation
            memory_before = self.monitor.process.memory_info().rss / 1024 / 1024

            # Perform switching operation
            mock_service.load_participant_data(participant_key, mode)
            mock_plot.set_data_and_restrictions(test_data["timestamps"], test_data["activity"], mode)

            # Capture memory after operation
            memory_after = self.monitor.process.memory_info().rss / 1024 / 1024

            memory_snapshots.append(
                {
                    "operation": i,
                    "mode": mode,
                    "memory_before": memory_before,
                    "memory_after": memory_after,
                    "memory_growth": memory_after - memory_before,
                }
            )

            # Force garbage collection every 10 operations
            if i % 10 == 9:
                gc_before = len(gc.get_objects()) if hasattr(gc, "get_objects") else 0
                gc.collect()
                gc_after = len(gc.get_objects()) if hasattr(gc, "get_objects") else 0

                gc_collections.append(
                    {"operation": i, "objects_before": gc_before, "objects_after": gc_after, "objects_collected": gc_before - gc_after}
                )

        final_memory = self.monitor.process.memory_info().rss / 1024 / 1024
        peak_memory = self.monitor.get_peak_memory_mb()

        self.monitor.stop_monitoring()

        # Analyze memory patterns
        total_growth = final_memory - initial_memory
        avg_operation_growth = sum(s["memory_growth"] for s in memory_snapshots) / len(memory_snapshots)
        max_operation_growth = max(s["memory_growth"] for s in memory_snapshots)

        # Check for memory leaks (continuous growth trend)
        growth_trend = []
        window_size = 10
        for i in range(window_size, len(memory_snapshots)):
            recent_avg = sum(s["memory_after"] for s in memory_snapshots[i - window_size : i]) / window_size
            older_avg = sum(s["memory_after"] for s in memory_snapshots[i - window_size * 2 : i - window_size]) / window_size
            growth_trend.append(recent_avg - older_avg)

        leak_detected = len(growth_trend) > 0 and sum(growth_trend) > 50  # 50MB trend growth

        return {
            "initial_memory_mb": initial_memory,
            "final_memory_mb": final_memory,
            "peak_memory_mb": peak_memory,
            "total_growth_mb": total_growth,
            "avg_operation_growth_mb": avg_operation_growth,
            "max_operation_growth_mb": max_operation_growth,
            "operations_count": operations,
            "memory_snapshots": memory_snapshots,
            "gc_collections": gc_collections,
            "leak_detected": leak_detected,
            "growth_trend": growth_trend,
        }

    def _generate_test_data(self, size: int) -> dict[str, Any]:
        """Generate test data for performance testing."""
        timestamps = pd.date_range(start="2021-04-20 12:00:00", periods=size, freq="30S")

        activity = np.random.poisson(50, size).astype(np.float64)

        return {"timestamps": timestamps.tolist(), "activity": activity.tolist(), "size": size}

    def _create_mock_service(self, test_data: dict[str, Any]) -> Mock:
        """Create mock service for performance testing."""
        service = Mock()  # Removed spec to allow dynamic attribute assignment

        def mock_load_data(participant_key, view_mode):
            # Simulate data processing time based on data size
            data_size = test_data["size"]
            processing_time = (data_size / 10000) * 0.01  # 10ms per 10k records
            time.sleep(processing_time)
            return True

        service.load_participant_data.side_effect = mock_load_data
        return service

    def _create_mock_plot_widget(self) -> Mock:
        """Create mock plot widget for performance testing."""
        plot = Mock()  # Removed spec to allow dynamic attribute assignment

        # Mock state
        plot.activity_data = []
        plot.timestamps = []
        plot.sleep_markers = []
        plot.current_view_hours = ViewMode.HOURS_24
        plot.vb = Mock()
        plot.vb.viewRange.return_value = [[0, 86400], [0, 300]]

        def mock_set_data(timestamps, activity, view_mode, **kwargs):
            # Simulate UI update time based on data size
            data_size = len(activity) if activity else 0
            ui_time = (data_size / 10000) * 0.005  # 5ms per 10k records
            time.sleep(ui_time)

            plot.activity_data = activity
            plot.timestamps = timestamps
            plot.current_view_hours = view_mode

        plot.set_data_and_restrictions.side_effect = mock_set_data

        return plot


class TestSwitchingPerformanceBenchmarks:
    """Test performance benchmarks for switching operations."""

    def test_data_source_switching_benchmarks(self):
        """Test data source switching performance across different data sizes."""
        benchmark = SwitchingPerformanceBenchmark()

        # Test with various data sizes
        data_sizes = [1000, 2880, 5760, 10000]  # Small to large datasets
        results = benchmark.benchmark_data_source_switching(data_sizes, iterations=3)

        assert len(results) == len(data_sizes)

        # Verify performance scaling
        for i, result in enumerate(results):
            assert result.data_size == data_sizes[i]
            assert result.total_time_ms > 0
            assert result.throughput_ops_per_sec > 0

            # Larger datasets should generally take more time
            if i > 0:
                prev_result = results[i - 1]
                time_ratio = result.total_time_ms / prev_result.total_time_ms
                size_ratio = result.data_size / prev_result.data_size

                # Time should scale roughly with data size (within reasonable bounds)
                # Using 5x multiplier to account for system variability (caching, CPU scheduling)
                assert time_ratio <= size_ratio * 5, f"Performance scaling issue: time ratio {time_ratio}, size ratio {size_ratio}"

        # Check that most operations pass performance thresholds
        passing_count = sum(1 for r in results if r.is_passing)
        assert passing_count >= len(results) * 0.7, f"Only {passing_count}/{len(results)} benchmarks passed"

    def test_view_mode_switching_benchmarks(self):
        """Test view mode switching performance."""
        benchmark = SwitchingPerformanceBenchmark()

        mode_transitions = [
            (ViewMode.HOURS_24, ViewMode.HOURS_48),
            (ViewMode.HOURS_48, ViewMode.HOURS_24),
            (ViewMode.HOURS_24, ViewMode.HOURS_24),  # Same mode
            (ViewMode.HOURS_48, ViewMode.HOURS_48),  # Same mode
        ]

        results = benchmark.benchmark_view_mode_switching(mode_transitions)

        assert len(results) == len(mode_transitions)

        # Same-mode transitions should be faster
        same_mode_results = [r for r in results if "24_to_24" in r.operation_name or "48_to_48" in r.operation_name]
        different_mode_results = [r for r in results if r not in same_mode_results]

        if same_mode_results and different_mode_results:
            avg_same_mode_time = sum(r.total_time_ms for r in same_mode_results) / len(same_mode_results)
            avg_different_mode_time = sum(r.total_time_ms for r in different_mode_results) / len(different_mode_results)

            # Same mode should be faster or comparable
            assert avg_same_mode_time <= avg_different_mode_time * 1.5, "Same-mode switching should be efficient"

    def test_rapid_switching_performance(self):
        """Test performance under rapid switching conditions."""
        benchmark = SwitchingPerformanceBenchmark()

        result = benchmark.benchmark_rapid_switching(switch_count=20, data_size=2880)

        assert result.operation_name == "rapid_switching_20_operations"
        assert result.total_time_ms > 0
        assert result.throughput_ops_per_sec > 0

        # Should maintain reasonable performance under rapid switching
        avg_time_per_switch = result.total_time_ms / 20
        assert avg_time_per_switch <= 100, f"Average time per switch too high: {avg_time_per_switch:.1f}ms"

        # Memory growth should be reasonable
        memory_growth = result.memory_after_mb - result.memory_before_mb
        assert memory_growth <= 100, f"Excessive memory growth: {memory_growth:.2f}MB"

    def test_memory_usage_patterns(self):
        """Test memory usage patterns during extended operations."""
        benchmark = SwitchingPerformanceBenchmark()

        memory_analysis = benchmark.benchmark_memory_usage_patterns(operations=50)

        # Verify memory analysis structure
        assert "initial_memory_mb" in memory_analysis
        assert "final_memory_mb" in memory_analysis
        assert "total_growth_mb" in memory_analysis
        assert "leak_detected" in memory_analysis
        assert len(memory_analysis["memory_snapshots"]) == 50

        # Memory growth should be reasonable (relaxed threshold for CI environments)
        total_growth = memory_analysis["total_growth_mb"]
        operations_count = memory_analysis["operations_count"]
        growth_per_operation = total_growth / operations_count

        # Use relaxed threshold - memory behavior varies significantly by environment
        assert growth_per_operation <= 20.0, f"Excessive memory growth per operation: {growth_per_operation:.2f}MB"

        # Only fail on extreme memory leaks (>500MB total growth for 50 ops)
        assert total_growth <= 500.0, f"Extreme memory growth detected: {total_growth:.2f}MB"

    def test_performance_regression_detection(self):
        """Test detection of performance regressions by comparing fast vs slow operations."""
        benchmark = SwitchingPerformanceBenchmark()

        # Baseline benchmark with small dataset
        baseline_results = benchmark.benchmark_data_source_switching([1000], iterations=3)
        baseline_time = baseline_results[0].total_time_ms

        # Benchmark with larger dataset (should take longer)
        larger_results = benchmark.benchmark_data_source_switching([5000], iterations=3)
        larger_time = larger_results[0].total_time_ms

        # Larger dataset should take more time (performance scales with data size)
        # This validates the benchmark can detect timing differences
        assert larger_time >= baseline_time * 0.5, "Benchmark should be sensitive to data size"

        # Both should complete in reasonable time (not infinite/stuck)
        assert baseline_time < 10000, f"Baseline too slow: {baseline_time:.2f}ms"
        assert larger_time < 30000, f"Larger dataset too slow: {larger_time:.2f}ms"

    def test_concurrent_performance_monitoring(self):
        """Test performance monitoring under concurrent operations."""
        monitor = PerformanceMonitor()

        # Start monitoring
        monitor.start_monitoring(interval_ms=50)

        # Simulate concurrent operations
        def simulate_work():
            for _ in range(10):
                # Simulate CPU and memory intensive work
                data = np.random.random(1000)
                np.sum(data**2)
                time.sleep(0.01)

        # Run multiple threads
        threads = []
        for _ in range(3):
            thread = threading.Thread(target=simulate_work)
            threads.append(thread)
            thread.start()

        # Let operations run
        time.sleep(0.5)

        # Wait for completion
        for thread in threads:
            thread.join()

        monitor.stop_monitoring()

        # Verify monitoring captured data
        assert len(monitor.measurements) >= 5, "Should capture multiple measurements"

        peak_memory = monitor.get_peak_memory_mb()
        avg_cpu = monitor.get_average_cpu_percent()
        memory_growth = monitor.get_memory_growth_mb()

        assert peak_memory > 0, "Should measure peak memory"
        assert avg_cpu >= 0, "Should measure CPU usage"
        assert isinstance(memory_growth, float), "Should calculate memory growth"

    def test_performance_threshold_validation(self):
        """Test performance threshold validation."""
        benchmark = SwitchingPerformanceBenchmark()

        # Test with small dataset (should pass)
        small_results = benchmark.benchmark_data_source_switching([1000], iterations=1)
        small_result = small_results[0]

        # Should pass performance threshold for small dataset
        assert small_result.is_passing, f"Small dataset should pass threshold: {small_result.total_time_ms}ms > {small_result.pass_threshold_ms}ms"

        # Verify threshold calculation scales with data size
        large_results = benchmark.benchmark_data_source_switching([10000], iterations=1)
        large_result = large_results[0]

        assert large_result.pass_threshold_ms > small_result.pass_threshold_ms, "Larger datasets should have higher thresholds"

    def test_benchmark_result_serialization(self):
        """Test that benchmark results can be serialized for reporting."""
        benchmark = SwitchingPerformanceBenchmark()

        results = benchmark.benchmark_data_source_switching([2880], iterations=1)
        result = results[0]

        # Verify all fields are accessible and serializable
        result_dict = {
            "operation_name": result.operation_name,
            "total_time_ms": result.total_time_ms,
            "data_load_time_ms": result.data_load_time_ms,
            "ui_update_time_ms": result.ui_update_time_ms,
            "memory_before_mb": result.memory_before_mb,
            "memory_after_mb": result.memory_after_mb,
            "throughput_ops_per_sec": result.throughput_ops_per_sec,
            "is_passing": result.is_passing,
        }

        # Should be able to convert to JSON
        import json

        json_str = json.dumps(result_dict)

        assert len(json_str) > 0, "Should serialize to JSON"

        # Should be able to reconstruct
        reconstructed = json.loads(json_str)
        assert reconstructed["operation_name"] == result.operation_name
        assert reconstructed["is_passing"] == result.is_passing


class TestMemoryMonitoring:
    """Test memory monitoring capabilities."""

    def test_memory_profile_capture(self):
        """Test memory profile capture accuracy."""
        monitor = PerformanceMonitor()

        # Capture initial profile
        monitor.start_monitoring()
        time.sleep(0.1)
        monitor.stop_monitoring()

        assert len(monitor.measurements) > 0, "Should capture measurements"

        # Verify measurement structure
        measurement = monitor.measurements[0]
        assert "timestamp" in measurement
        assert "memory" in measurement
        assert "cpu_percent" in measurement

        memory_profile = measurement["memory"]
        assert memory_profile.rss_mb > 0, "Should measure RSS memory"
        assert memory_profile.vms_mb > 0, "Should measure VMS memory"
        assert isinstance(memory_profile.gc_generation_0, int), "Should track GC stats"

    def test_memory_leak_detection(self):
        """Test memory leak detection during operations."""
        monitor = PerformanceMonitor()

        # Force GC before starting to get clean baseline
        gc.collect()

        # Create intentional memory growth
        monitor.start_monitoring()

        large_objects = []
        for i in range(20):
            # Create large objects that accumulate (~800KB each for more reliable detection)
            large_object = np.random.random(100000)
            large_objects.append(large_object)
            time.sleep(0.01)

        monitor.stop_monitoring()

        memory_growth = monitor.get_memory_growth_mb()

        # Should detect some memory activity (relaxed threshold for environment variance)
        # The test validates the monitoring works, not exact memory values
        assert memory_growth >= 0, f"Memory growth should be non-negative: {memory_growth:.2f}MB"

        # Verify large_objects actually consumed memory (sanity check)
        total_size_mb = sum(obj.nbytes for obj in large_objects) / (1024 * 1024)
        assert total_size_mb > 10, f"Test objects should be >10MB, got {total_size_mb:.2f}MB"

        # Clean up
        del large_objects
        gc.collect()

    def test_gc_impact_measurement(self):
        """Test measurement of garbage collection impact."""
        monitor = PerformanceMonitor()

        # Create objects for GC
        test_objects = []
        for _ in range(1000):
            test_objects.append([1, 2, 3, 4, 5] * 100)

        monitor.start_monitoring()

        # Force garbage collection
        gc_stats_before = gc.get_count()
        gc.collect()
        gc_stats_after = gc.get_count()

        time.sleep(0.1)
        monitor.stop_monitoring()

        # Should capture GC activity
        if monitor.measurements:
            gc_measurements = [m["memory"].gc_generation_0 for m in monitor.measurements]
            assert len(set(gc_measurements)) > 1 or gc_stats_before != gc_stats_after, "Should detect GC activity"

        # Clean up
        del test_objects
        gc.collect()
